{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80af05a0",
   "metadata": {},
   "source": [
    "# 공부해야 할 주제들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e03600",
   "metadata": {},
   "source": [
    "## 데이터 마이닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68c2a52",
   "metadata": {},
   "source": [
    "### 지도학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a4d400",
   "metadata": {},
   "source": [
    "1. 의사결정나무: CART, C5.0, C4.5, CHAID, 분리기준 (카이제곱통계량 p값, 지니 지수, 엔트로피 지수, F통계량, 분산의 감소량), 가지치기\n",
    "2. 앙상블분석: 배깅, 부스팅(Adaboost), 랜덤포레스트, 스태킹, 엑스트라트리, 에이다부스트\n",
    "3. 인공신경망\n",
    "- 활성화함수(계단함수, 부호함수, 시그모이드 함수, relu함수, softmax 함수)\n",
    "- 다층퍼셉트론\n",
    "- ANN, DNN, CNN, RNN, GAN(InfoGAN, CycleGAN), RBM, DBN\n",
    "- MLP-CNN-RNN 구현 및 비교\n",
    "- ResNet, DenseNet\n",
    "- AutoEncoder, VAE, DQN\n",
    "- 진화 학습 (유전 알고리즘)\n",
    "- 강화학습 (마르코프 결정과정)\n",
    "- 대칭가중치와 심층신뢰 네트워크\n",
    "4. 회귀분석\n",
    "- 가정검토(선형성, 등분산성-잔차도, 정규성-히스토그램/QQplot/Shapiro-wilk, 오차항의 독립성-더빈왓슨검정)\n",
    "- 단순선형회귀분석(회귀계수 검정, 결정계수 계산-SST/SSR/SSE, 회귀직선의 적합도 검토)\n",
    "- 다중선형회귀분석(회귀계수 검정, 회귀식, 결정계수 계산, 모형의 통계적 유의성, 교호작용, 다중공선성-PCA회귀, VIF 상위변수 제거)\n",
    "- 다항회귀분석\n",
    "- 스플라인 회귀\n",
    "- 로지스틱 회귀\n",
    "- 최적회귀방정식(전진선택법, 후진제거법, 단계적선택법 - AIC/BIC)\n",
    "- 정규화 선형회귀 Regularized Linear Regression (Ridge회귀, Lasso회귀, Elastic Net 회귀)\n",
    "- 일반화 선형회귀 Generalized Linear Regression\n",
    "- 회귀분석의 기울기에 영향을 주는 영향점 진단: Cook's Distance, DFBETAS, DFFITS, Leverage H\n",
    "- 변수 선택의 기준: 결정계수, Mallow's Cp, AIC/BIC\n",
    "5. 최근접 이웃법 (KNN), 가우시안 혼합모델\n",
    "6. 베이지안 분류\n",
    "7. SVM\n",
    "8. 판별분석\n",
    "9. 사례기반 추론 (Case based reasoning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e10d759",
   "metadata": {},
   "source": [
    "### 비지도학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f712e7cf",
   "metadata": {},
   "source": [
    "1. 연관규칙학습 (패턴인식): 장바구니분석(Apriori, FP Growth, FPV, Eclat), 연관규칙, 서열분석 (순차패턴, 시차-연관분석; Sequence Analysis)\n",
    "2. 주성분분석(Scree plot, 누적기여율, 주성분 별 가중치, Biplot) 및 요인분석\n",
    "- 차원축소, 특성추출, 매니폴드학습, PCA, NMF\n",
    "3. 군집분석\n",
    "- 계층적군집: 합병형 Bottom-up 방식(최단연결법, 평균연결법, 와드연결법, 최장연결밥, 중심연결법), 분리형 top-down 방식 (다이아나 방법), 덴드로그램\n",
    "- 분할적 군집(비계층적군집): 프로토타입 centroid-based (K-centroid 군집, K-means 군집, K-median 군집, K-medoid 군집, Fuzzy 군집), 분포기반GMM(혼합분포군집; EM알고리즘, 로그-가능도 함수), 밀도기반(중심밀도군집, DBSCAN, OPTICS, DENCLUE), 격자기반(STING, WaveCluster, CLIQUE)\n",
    "- 거리: 유클리디안 거리, 마할라노비스 거리, 체비셰프 거리, 맨하탄 거리, 캔버라 거리, 민코우스키 거리, 자카드 거리, 코사인 거리\n",
    "- SOM\n",
    "- 타당성지표: 실루엣 계수, Dunn Index\n",
    "4. 사회연결망분석 (Social network)\n",
    "- 네트워크 구조 파악: 중심성, 밀도, 구조적틈새, 집중도 등\n",
    "- 커뮤니티 발견: walk trap, edge-betweenness\n",
    "- Giraph 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f1779",
   "metadata": {},
   "source": [
    "### 기타 통계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbce0ba",
   "metadata": {},
   "source": [
    "1. 탐색적 자료 분석: 요약, 기술통계 (평균, 표준편차, 중위수, 사분위수, 변동계수, 최빈값, 그래프, 왜도, 첨도), 줄기잎그림, 도넛차트, 히스토그램, 상자수염 그림\n",
    "2. 데이터와 표본분포 (정규분포, T분포, F분포, 이항분포, 포아송 분포 등)\n",
    "3. 유의성검정:\n",
    "    1. t-test\n",
    "    - 정규성검정: 콜모고로프 스미르노프 검정, QQ도, Anderson-Darling test, 샤크로-윌크 검정\n",
    "    - 등분산검정\n",
    "    - 등분산성만족 못할시: Welch two sample t-test\n",
    "    - 일표본 T검정, 대응표본 t검정, 독립표본 t검정\n",
    "    2. 분산분석(ANOVA)\n",
    "    - 일원배치 분산분석: 분산분석표, 사후분석(던칸의 MRT, 피셔의 LSD, Scheffe의 방법)\n",
    "    - 이원배치 분산분석: 분산분석표, 교호작용\n",
    "    3. 교차분석: 적합도 검정, 독립성 검정(교차표), 동질성 검정(교차표)\n",
    "    4. 다중검정\n",
    "    5. 공분산, 상관분석 (피어슨, 스피어만, 켄달 타우, 상관계수 검정)\n",
    "4. 시계열분석:\n",
    "- 분해시계열, ARIMA모델 (ACF/PACF를 통한 모델 결정)\n",
    "- ARIMA(p,d,q) - 정상성 (ADF, KPSS test), 차분, ACF, PACF, Ljung-Box test\n",
    "- SARIMA(p,d,q)(P,D,Q)[s]\n",
    "5. 다차원척도법: 계량적MDS, 비계량적 MDS\n",
    "6. 비모수검정: 부호검정, 윌콕슨의 순위합 검정, 윌콕슨의 부호순위합검정, 만위트니의 U검정, 런검정\n",
    "7. 성과분석\n",
    "- 분류분석: 정분류율, 오분류율, 특이도, 민감도, 정확도, 재현율, F1 Score, RoC Curve, AUROC, Lift Chart (Frequency of buy, captured response, response, lift), cross validation\n",
    "- 연관성분석: 지지도, 신뢰도, 향상도\n",
    "- Bias-variance Trade-off\n",
    "- 과대적합, 과소적합, 일반화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13ecbf",
   "metadata": {},
   "source": [
    "## 텍스트 마이닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426588a7",
   "metadata": {},
   "source": [
    "1. 말뭉치 전처리와 가공, 텍스트 벡터화와 변환 파이프라인, 텍스트 데이터 플래트닝, 필터링, 청킹\n",
    "- Tokenization, Pos Tagging, Stemming/Lemmazation, Remove Stopwords, One-hot encoding, N-Gram, TF-IDF, Cosine Similarity\n",
    "2. 텍스트 분석을 위한 분류, 텍스트 유사성 군집화, 문맥인식 텍스트 분석\n",
    "3. 텍스트 시각화, 텍스트 그래프 분석\n",
    "4. 감성분석\n",
    "5. 워드클라우드 분석\n",
    "6. 텍스트마이닝 모델링\n",
    "- 나이브 베이지안 분류\n",
    "- LDA (Latent Dirichlet Allocation)\n",
    "- Word2Vec\n",
    "- Perplexity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9c27c7",
   "metadata": {},
   "source": [
    "## 데이터 가공 및 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadcfc35",
   "metadata": {},
   "source": [
    "1. 전처리\n",
    "- 결측값 처리: 단순대치, 평균 대치, 단순확률 대치 (Hot-deck, nearest neighbor), 다중 대치, knnImputation, centralimputation\n",
    "- 클래스불균형: 업샘플링 (SMOTE, Boaderline SMOTE, Adasyn), 다운샘플링\n",
    "- 이상값 처리: 극단값 절단, 조정\n",
    "- 변수 변환, 스케일링: 수치형 변수 변환(로그변환, 제곱근변환, 지수변환, 제곱변환, Box-cox 변환, 표준화, 정규화), 범주형 변수 변환(범주형 변수 인코딩, 대규모 범주형 변수처리), 날짜 및 변수 변환,  피쳐스케일링\n",
    "- 원핫인코딩(더미변수), 컬럼 트랜스퍼, 구간분할, 이산화, 피쳐선택\n",
    "2. 표본 추출: 단순랜덤 추출법, 계통추출법, 집락추출법, 층화추출법\n",
    "3. 데이터 분할: 구축/검정/시험용, 홀드아웃방법, 교차확인방법 (10 fold 교차분석), 부트스트랩\n",
    "4. 그래프 그리기:\n",
    "- 산점도, 막대그래프, 선그래프, 히트맵, 서브플롯, 트리맵, 도넛차트, 버블차트, 히스토그램, 체르노프 페이스, 스타차트, 다차원척도법, 평행좌표계\n",
    "- 도식화와 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf208a2",
   "metadata": {},
   "source": [
    "## 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8b299",
   "metadata": {},
   "source": [
    "1. Numpy 배열과 벡터 계산, Pandas 시작하기\n",
    "2. 모델구축, 모델튜닝 (하이퍼파라미터), 그리드서치, 기타기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411cf385",
   "metadata": {},
   "source": [
    "# 기출문제\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753111dc",
   "metadata": {},
   "source": [
    "## 24회차"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8fc5272",
   "metadata": {},
   "source": [
    "1. 머신러닝 (data: 학생 결석일수 관련 데이터, 독립변수 12개 - 성별, 나이, 부모와 같이 사는지 여부, 아버지 학력, 어머니 학력, 보호자, 집학교 거리, 공부 시간, F학점 맞은 횟수, 가족 관계, 여가시간, 총 395개의 관측치) -50점\n",
    "\n",
    "- 시각화 포함하여 탐색적 분석하기\n",
    "- 시각화 포함하여 전처리 하기\n",
    "- 이밖에 추가할 수 있는 전처리를 하고, 그 이유와 기대효과를 쓰기\n",
    "- 해당 데이터셋에서 학생결석 일수를 예측하는데에 적용 가능한 알고리즘 3개를 언급하고 그 중 2개를 선택하고, 그 이유를 설명하기\n",
    "- 해당 모델에 성능 평가 지표를 뭘로 쓸건지 그 이유를 설명하기\n",
    "- 선정한 2개 알고리즘으로 실제 코딩한 후 성능 평가를 통해 비교하고 설명하기 (시각화 포함)\n",
    "- 실제로 사용가능한 모델인지 설명\n",
    "- 다양한 환경에서 적용할 수 있는 방안 설명\n",
    "- 추가적으로 모델 개선할 수 있는 방안 설명\n",
    "\n",
    "2. 통계분석 - 50점\n",
    "\n",
    "- 광고비(범주형 변수, 높음과 낮음으로 적혀있음), 연구개발비(수치형 변수, 수치 적혀있음), 판매액(수치형 변수, 수치 적혀있음), 전체 관측치는 10개로 소규모 데이터. 광고비와 연구개발비가 독립변수, 판매액이 종속변수.\n",
    "    - 광고비를 가변수화해서 다중선형회귀방정식을 만들고 회귀계수를 검정하기\n",
    "    - 회귀 모형을 검정하기\n",
    "- A생산라인의 제품 평균은 5.7mm이고 표준편차는 0.03, B생산라인의 제품 평균은 5.6mm이고 표준편차는 0.04라면 5%유의수준으로 두 제품의 평균이 차이가 있는지 여부를 검정하기 (Z통계량도 제공 - Z(0.05) = 1.65, 위의 구체적인 숫자는 실제 시험 때 숫자랑 정확하게 맞지는 않음)\n",
    "    - 귀무가설과 대립가설 세우기\n",
    "    - 두 평균이 차이가 있는지 검정 하기 \n",
    "- 베이지안 분류 문제 - 바이러스 감염 분류표를 보고 베이지안 분류 방법을 사용해 양성으로 예측된 사람이 실제로 양성일 확률을 구하는 문제\n",
    "    - 수치는 실제 시험과 다를 수 있음\n",
    "    |구분|양성(실제)|음성(실제)|\n",
    "    |---|---|---|\n",
    "    |양성(예측)|370|10|\n",
    "    |실제(예측)|15|690|\n",
    "  \n",
    "\n",
    "- 9개 정도의 숫자 표본에 대해 단일표본 T검증을 진행하여 아래 내용을 구하기\n",
    "    - 위 표본의 평균에 대한 신뢰구간 구하기\n",
    "    - 과거에 해당 표본의 모집단의 표준편차가 0.4일 때 표본 평균에 대한 신뢰구간 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3a3211",
   "metadata": {},
   "source": [
    "## 23회차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920d02c7",
   "metadata": {},
   "source": [
    "1. 머신러닝 (data: 객실 사용 여부 관련 데이터, 독립변수는 온두, 습도, CO2, 빛, 총 290개 가량의 관측치)\n",
    "\n",
    "- 분류문제, class 불균형 데이터로 0이 12%, 1이 88%로 구성\n",
    "- 데이터 탐색하고 탐색 결과 제시\n",
    "- 결측치 탐색하고 대체 방법 및 근거 제시\n",
    "- 추가적으로 데이터 질을 향상시킬만한 내용 작성 (구현 없이 설명만해도 됨)\n",
    "- 데이터 불균형을 시각화하여 식별하고 불균형 판단근거 작성\n",
    "- 오버샘플링 기법 설명하고 비교한 뒤 2개 기법 선정 및 근거제시\n",
    "- 선정한 이유 작성하고, 원데이터 포함 3개 데이터 세트 구성\n",
    "- 오버샘플링 데이터와 원데이터 사용하여 정확도 측면 모델 하나 속도 측면 모델 하나 선정\n",
    "- 선정한 이유 작성\n",
    "- 원 데이터와 오버샘플링 데이터를 가지고 각각 분류하여 오버샘플링이 성능에 미친 영향에 대해 작성\n",
    "\n",
    "2. 통계분석\n",
    "- 공장에서는 진공관 수명이 1만 시간이라고 주장하여 품질관리팀에서 12개 샘플을 뽑았음 유의수준 5%에서 부호 검정하시오\n",
    "    - 연구가설 귀무가설 작성(5)\n",
    "    - 유효한 샘플의 수를 계산(5)\n",
    "    - 검정통계량 및 연구가설 채택 여부 작성(5)\n",
    "- 코로나 시계열 데이터 5만 관측치 가량, 날짜, 코로나 누적확진자 등 변수 3개\n",
    "    - ACF 사용해서 distance 계산 (10)\n",
    "    - 계층적 군집 분석을 위해 덴드로그램 작성 (10)\n",
    "- 사회과학 자연과학 공학 세개 학과의 평점 조사표: 3.5-4.5, 2.5-3.5, 1.5-2.5 3개 점수구간이 row index이며 학과가 컬럼이고 값으로는 사람 수가 들어가있음. 학과와 성적이 관계있는지 검정하시오\n",
    "    - 연구가설 귀무가설 작성(5)\n",
    "    - 학과와 성적이 독립일 때 기댓값 구하시오(5)\n",
    "    - 검정통계량 구하고 연구가설 채택여부 작성(5- )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98627fd",
   "metadata": {},
   "source": [
    "## 22회차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a7efde",
   "metadata": {},
   "source": [
    "1. 머신러닝 (data: Pima Indian Diabetes)\n",
    "- 탐색적 데이터 분석: 결측치 확인, 히스토그램/박스플롯/페어플롯, 타겟변수 분포 그래프의 불균형 확인, 변수 전체의 상관관계, 이상치 처리 방안 제시, 위의 전처리 단계에서 얻은 향수 분석 시 고려사항 작성\n",
    "- 클래스 불균형 처리: 오버샘플링, 언더샘플링 과정 설명하고 결과 작성, 둘 중 선택하고 그 이유 설명\n",
    "- 모델링: 최소 3개 이상 알고리즘 제시하고 정확도 측면의 모델 1개와 속도 측면의 모델 1개를 구현, 모델 비교하고 결과 설명, 속도 개선을 위한 차원 축소 설명하고 수행, 성능과 속도 비교하여 결과 작성\n",
    "\n",
    "2. 통계분석 (data: 금속 성분 함유량 데이터)\n",
    "- 제품에 금속 재질 함유량의 분산이 1.3을 넘으면 불량이라고 보는데 제조사별로 차이가 남. 분산 검정 수행. 유의확률 0.05\n",
    "- 불량률 관리도에 따른 관리 중심선, 관리 상한선, 하한선 구하기 (각 공식 있음), 관리도 시각화\n",
    "\n",
    "3. 데이터 없음\n",
    "- 표에 제품 1, 2를 만드는데 재료 a, b, c가 사용됨. 제품 1, 2는 각각 12만원, 18만원. 재료는 한정적일 때 최대 수익을 낼 수 있을 제품 1과 제품2의 개수 구하기\n",
    "\n",
    "4. 데이터 없음\n",
    "- 상품 a와 b가 있을 때 구매 패턴이 aa bb aaaa bbbb a b 등으로 나타날 때 두 상품의 연관성 유무를 검정할 것\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47233056",
   "metadata": {},
   "source": [
    "## 21회차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b82ea",
   "metadata": {},
   "source": [
    "1. 머신러닝 (data: 학생 성적데이터: 독립변수 - school, sex, paid, activities, famrel, freetime, goout, dalc, walc, health, absences, 타겟변수 - grade)\n",
    "- 시각화 포함 탐색적 자료분석\n",
    "- 결측치 식별 및 결측치를 예측하는 방법 2가지 쓰고, 선택한 이유를 설명\n",
    "- 범주형 변수 인코딩이 필요한 경우를 식별하고, 변환을 적용하고, 선택한 이유를 설명\n",
    "- 데이터 분할 방법을 2가지 쓰고 적절한 데이터 분할을 적용. 선택한 이유를 설명\n",
    "- svm, xgboost, randomforest 3개 알고리즘의 공통점을 쓰고, 예측 분석에 적합한 알고리즘인지 설명\n",
    "- 3가지 방법으로 모두 모델링 해보고 가장 적합한 알고리즘 선택하고 이유 설명. 한계점 설명하고 보완 가능한 부분 설명. 현업에서 사용시 주의할 점 등에 대해 기술.\n",
    "\n",
    "2. 머신러닝 (data: 연속형 독립변수 여러개의 소규모 데이터. 변수명은 순서대로 x1~x10 이라 의미 없음)\n",
    "- 데이터 8:2로 분할하고 선형회귀 적용. 결정계수와 rmse 구하기.\n",
    "- 데이터 8:2로 분할하고 릿지 회귀 적용. alpha 값을 0부터 1까지 0.1단위로 모두 탐색해서 결정계수가 가장 높을 때의 알파를 찾고, 해당 알파로 다시 모델을 학습해서 결정계수와 rmse를 계산\n",
    "- 데이터 8:2로 분할하고 라쏘 회귀 적용. alpha 값을 0부터 1까지 0.1단위로 모두 탐색해서 결정계수가 가장 높을 때의 알파를 찾고, 해당 알파로 다시 모델을 학습해서 결정계수와 rmse를 계산\n",
    "\n",
    "3. 시각화 (data: 독립변수 하나 종속변수 하나 소규모 데이터)\n",
    "- 다항 회귀를 3차까지 적용하고 각 차수별 스캐터 플롯과 계수와 회귀선 그리기\n",
    "\n",
    "4. 통계분석:\n",
    "- 이원분산분석을 수행하고 통계표 작성\n",
    "- 변수 3개(하나는 abcde 각각을 값으로 갖는 범주형 변수, 나머지 두 개는 수치형 연속변수)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c397049",
   "metadata": {},
   "source": [
    "## 20회차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d29cb3",
   "metadata": {},
   "source": [
    "1. 시계열분석(data: 1년 간의 온도 데이터; 년월일, 실제온도, 지연값1, 지연값2, 친구의 예측값, 예측최소값, 예측값, 예측최대값 등 포함)\n",
    "- 데이터 전처리: 필요없는 열처리, 데이터 전처리 증명, train/test set 나눌 방법 설명\n",
    "- 랜덤포레스트로 검증 및 분석: 예측한계선 설정하는 방법 설명, 파라미터 조정을 통해 성능 강화, 컬럼별 중요도 시각화\n",
    "- SVM으로 검증 및 분석: 예측한계선 설정하는 방법 설명,  파라미터 조정하여 성능 강화, 컬럼별 중요도 시각화\n",
    "- 두 모델의 장단점 설명, 어느 모델이 더 좋은지 선택 및 설명, 선택한 모델의 한계점 및 해결방법\n",
    "\n",
    "2. 군집분석(data: 가구별 15분 단위의 전력사용량; 년월일, 시간, 가구코드, 전력사용량 등 포함)\n",
    "- 가구별, 15분 단위 전력 사용량의 합을 구하고, 이 데이터를 군집화하여 표 완성시키기 (가구코드, Date, 전력사용량의합, Cluster)\n",
    "- 히트맵으로 시각화: 그룹별로 15분마다 전력 사용량을 요일별로 평균낸 것을 시각화\n",
    "\n",
    "3. 회귀분석\n",
    "- train/test 7:3 분할 및 검증 후 R2 score, RMSE, 정확도(공식 주어짐) 지표 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce2e7d3",
   "metadata": {},
   "source": [
    "## 19회차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f0418e",
   "metadata": {},
   "source": [
    "1. 기계학습(data: credit 데이터 - 고객 이탈 여부 분류하는 문제, 독립변수는 성별, 나이, 카드등급, 소득 등)\n",
    "- 데이터 전처리 및 시각화: 연속형 변수와 문자로된 범주형 변수 처리\n",
    "- 훈련용 데이터와 검증용 데이터를 7:3으로 분할, 분류 분석 3개 실시, 혼동행렬 만들기\n",
    "- 위의 분류 분석 3개를 앙상블하여 별도로 주어지는 credit test.cssv파일의 credit을 예측하고 result.csv로 제출\n",
    "\n",
    "2. 통계분석(data: Traffic EPS 시계열 분석 - 매년 분기별로 작성된 20년치 데이터)\n",
    "- 시계열 데이터의 정규성과 이분산성을 설명하기 위한 시각화\n",
    "- 데이터가 정규성이 아니라면 고정 시계열이 있는지 확인하고 이를 처리\n",
    "- SARIMA 분석을 통해 여러 파라미터를 적용해보고 가장 성능이 좋은 것을 제시\n",
    "- 위 모델의 잔차와 잡음 시각화 및 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47e08e4",
   "metadata": {},
   "source": [
    "## 18회차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c7c4d",
   "metadata": {},
   "source": [
    "1. 분류분석, 군집분석(SOM)\n",
    "\n",
    "2. 텍스트마이닝: 문자열 전처리, 워드클라우드\n",
    "\n",
    "3. 시계열: 정상성 체크 및 시계열 예측\n",
    "\n",
    "4. 잔차 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a3dd1b",
   "metadata": {},
   "source": [
    "## 17회차"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed28141",
   "metadata": {},
   "source": [
    "1. 머신러닝(data: Housing data - log1p로 정규화시킴)\n",
    "- EDA, Preprocessing\n",
    "- 모델링하고 예측\n",
    "- 하이퍼파라미터 조절하여 오차 줄이기, 평가지표는 RMAE\n",
    "\n",
    "2. 시계열분석 및 시각화(data: Covid19 - 일별 확진자수, 일별 완치자수로 데이터 가공 필요)\n",
    "- 코로나 위험지수를 만들고, 그 위험지수에 대한 설명을 적고, 위험지수가 높은 국가들 10개를 선정해서 시각화\n",
    "- 한국의 코로나 확진자 예측: 선형 시계열모델, 비선형시계열 모델 2개 만들기\n",
    "\n",
    "3. 통계분석(data: 설문조사 - A~S까지의 그룹이 설문조사에 응답했고 중간에 반대 문항이 들어가 있음)\n",
    "- 그룹별 통계치 계산\n",
    "- 탐색적 요인분석을 표로 작성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4306a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
